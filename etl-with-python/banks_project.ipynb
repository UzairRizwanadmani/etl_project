{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Saylani Mass Training Program**\n",
    "### **Cloud Data Engineering Module by Qasim Hassan**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A basice Extract, Transform and Load (ETL) pipeline using web scrapping, pandas and sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting icecream\n",
      "  Downloading icecream-2.1.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting colorama>=0.3.9 (from icecream)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting pygments>=2.2.0 (from icecream)\n",
      "  Downloading pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting executing>=0.3.1 (from icecream)\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting asttokens>=2.0.1 (from icecream)\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting six>=1.12.0 (from asttokens>=2.0.1->icecream)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
      "Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Downloading pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.3/1.2 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 0.5/1.2 MB 670.4 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 0.8/1.2 MB 931.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.0/1.2 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 943.4 kB/s eta 0:00:00\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: six, pygments, executing, colorama, asttokens, icecream\n",
      "Successfully installed asttokens-2.4.1 colorama-0.4.6 executing-2.1.0 icecream-2.1.3 pygments-2.18.0 six-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install icecream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "# from icecream import ic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 0: Maintaining a Log File\n",
    "This step is done to record the logs while performing ETL and it is not neccessary in an ETL Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('abc.txt','a')as f:\n",
    "    f.write(\"welcome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message):\n",
    "    \"\"\"This function logs the mentioned message of a given stage of the\n",
    "    code execution to a log file. Function returns nothing\"\"\"\n",
    "\n",
    "    with open('code_log.txt', 'a') as f:\n",
    "        f.write(f'{datetime.now()}: {message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url=\"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "# soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "# table = soup.find('span', string=table_attribs).find_next('table')\n",
    "# df = pd.read_html(StringIO(str(table)))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(url, table_attribs):\n",
    "    \"\"\" This function aims to extract the required\n",
    "    information from the website and save it to a data frame. The\n",
    "    function returns the data frame for further processing. \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(requests.get(url).text, 'html.parser')\n",
    "    table = soup.find('span', string=table_attribs).find_next('table')\n",
    "    df = pd.read_html(StringIO(str(table)))[0]\n",
    "\n",
    "    log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv('./input/exchange_rate.csv', index_col=0).to_dict()['Rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2697016640.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[35], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    df['MC_GBP_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['GBP'], 2)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "exchange_rate = pd.read_csv(csv_path, index_col=0).to_dict()['Rate']\n",
    "\n",
    "    df['MC_GBP_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['GBP'], 2)\n",
    "    df['MC_EUR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['EUR'], 2)\n",
    "    df['MC_INR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['INR'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, csv_path):\n",
    "    \"\"\" This function accesses the CSV file for exchange rate\n",
    "    information, and adds three columns to the data frame, each\n",
    "    containing the transformed version of Market Cap column to\n",
    "    respective currencies\"\"\"\n",
    "\n",
    "    exchange_rate = pd.read_csv(csv_path, index_col=0).to_dict()['Rate']\n",
    "\n",
    "    df['MC_GBP_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['GBP'], 2)\n",
    "    df['MC_EUR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['EUR'], 2)\n",
    "    df['MC_INR_Billion'] = round(df['Market cap (US$ billion)'] * exchange_rate['INR'], 2)\n",
    "\n",
    "    a = df['MC_EUR_Billion'][4]\n",
    "    print(a)\n",
    "    log_progress('Data transformation complete. Initiating Loading process')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_csv(df, output_path):\n",
    "    \"\"\" This function saves the final data frame as a CSV file in\n",
    "    the provided path. Function returns nothing.\"\"\"\n",
    "\n",
    "    df.to_csv(output_path)\n",
    "\n",
    "    log_progress('Data saved to CSV file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'database_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sqlite3\u001b[38;5;241m.\u001b[39mconnect(database_name) \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[0;32m      2\u001b[0m         load_to_db(df, conn, table_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'database_name' is not defined"
     ]
    }
   ],
   "source": [
    "with sqlite3.connect(database_name) as conn:\n",
    "        load_to_db(df, conn, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_db(df, sql_connection, table_name):\n",
    "    \"\"\" This function saves the final data frame to a database\n",
    "    table with the provided name. Function returns nothing.\"\"\"\n",
    "\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "    log_progress('Data loaded to Database as a table, Executing queries')\n",
    "\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    \"\"\" This function runs the query on the database table and\n",
    "    prints the output on the terminal. Function returns nothing. \"\"\"\n",
    "\n",
    "    cursor = sql_connection.cursor()\n",
    "    cursor.execute(query_statement)\n",
    "    result = cursor.fetchall()\n",
    "\n",
    "    log_progress('Process Complete')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                                Bank name  Market cap (US$ billion)\n",
      "0     1                           JPMorgan Chase                    432.92\n",
      "1     2                          Bank of America                    231.52\n",
      "2     3  Industrial and Commercial Bank of China                    194.56\n",
      "3     4               Agricultural Bank of China                    160.68\n",
      "4     5                                HDFC Bank                    157.91\n",
      "5     6                              Wells Fargo                    155.87\n",
      "6     7                        HSBC Holdings PLC                    148.90\n",
      "7     8                           Morgan Stanley                    140.83\n",
      "8     9                  China Construction Bank                    139.82\n",
      "9    10                            Bank of China                    136.81\n",
      "146.86\n",
      "[(1, 'JPMorgan Chase', 432.92, 346.34, 402.62, 35910.71), (2, 'Bank of America', 231.52, 185.22, 215.31, 19204.58), (3, 'Industrial and Commercial Bank of China', 194.56, 155.65, 180.94, 16138.75), (4, 'Agricultural Bank of China', 160.68, 128.54, 149.43, 13328.41), (5, 'HDFC Bank', 157.91, 126.33, 146.86, 13098.63), (6, 'Wells Fargo', 155.87, 124.7, 144.96, 12929.42), (7, 'HSBC Holdings PLC', 148.9, 119.12, 138.48, 12351.26), (8, 'Morgan Stanley', 140.83, 112.66, 130.97, 11681.85), (9, 'China Construction Bank', 139.82, 111.86, 130.03, 11598.07), (10, 'Bank of China', 136.81, 109.45, 127.23, 11348.39)]\n",
      "[(151.98700000000002,)]\n",
      "[('JPMorgan Chase',), ('Bank of America',), ('Industrial and Commercial Bank of China',), ('Agricultural Bank of China',), ('HDFC Bank',)]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    url = 'https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks'\n",
    "    output_csv_path = './Largest_banks_data.csv'\n",
    "    database_name = 'Banks.db'\n",
    "    table_name = 'Largest_banks'\n",
    "    #\n",
    "    log_progress('Preliminaries complete. Initiating ETL process')\n",
    "    #\n",
    "\n",
    "    df = extract(url, 'By market capitalization')\n",
    "    print(df)\n",
    "\n",
    "    transform(df, './input/exchange_rate.csv')\n",
    "\n",
    "    load_to_csv(df, output_csv_path)\n",
    "\n",
    "    with sqlite3.connect(database_name) as conn:\n",
    "        load_to_db(df, conn, table_name)\n",
    "\n",
    "        print(run_query('SELECT * FROM Largest_banks', conn))\n",
    "\n",
    "        print(run_query('SELECT AVG(MC_GBP_Billion) FROM Largest_banks', conn))\n",
    "\n",
    "        print(run_query('SELECT \"Bank name\" FROM Largest_banks LIMIT 5', conn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
